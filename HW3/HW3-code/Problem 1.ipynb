{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "\n",
    "'''reading from Database using pandas'''\n",
    "xls = pd.ExcelFile('LSVT_voice_rehabilitation.xlsx')\n",
    "df_data = pd.read_excel(xls, 'Data')\n",
    "df_target = pd.read_excel(xls, 'Binary response')\n",
    "df_demographics = pd.read_excel(xls, 'Subject demographics')\n",
    "\n",
    "'''10-fold cross validation '''\n",
    "\n",
    "X = df_data.values\n",
    "y = df_target.values\n",
    "\n",
    "X_folds = np.array_split(X, 10)\n",
    "y_folds = np.array_split(y, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Support vector machine implementation using 10-fold '''\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def SVMClassification(svc):\n",
    "    scores = list()\n",
    "    f1_scores = list()\n",
    "    for k in range(10):\n",
    "    \n",
    "        X_train = list(X_folds)\n",
    "        X_test = X_train.pop(k)\n",
    "        X_train = np.concatenate(X_train)\n",
    "\n",
    "        y_train = list(y_folds)\n",
    "        y_test = y_train.pop(k)\n",
    "        y_train = np.concatenate(y_train)\n",
    "\n",
    "        svc = make_pipeline(StandardScaler(), svc)\n",
    "        model = svc.fit(X_train,np.ravel(y_train))\n",
    "        scores.append(model.score(X_test, y_test))\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "        f1_scores.append(f1_score(y_test[:,0], y_pred, average='micro'))\n",
    "        \n",
    "    avg_scores = sum(scores)/10\n",
    "    avg_f1 = sum(f1_scores)/10\n",
    "    \n",
    "    return (avg_scores,avg_f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes:\n",
    "\n",
    "## 1. StandardScaler \n",
    "The main idea is to normalize/standardize i.e. μ = 0 and σ = 1 your features/variables/columns of X, individually, before applying any machine learning model. Thus, StandardScaler() will normalize the features i.e. each column of X, INDIVIDUALLY so that each column/feature/variable will have μ = 0 and σ = 1.\n",
    "\n",
    "Note that non-tree models models such as SVM, LDA etc. are often hugely dependent on normalization.\n",
    "\n",
    "## 2. micro\n",
    "micro parameter in f1-score Calculate metrics globally by counting the total true positives, false negatives and false positives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear accuracy    0.7852564102564104\n",
      "Linear F1-measure  0.7852564102564104\n"
     ]
    }
   ],
   "source": [
    "svc = svm.SVC(kernel = 'linear',max_iter=10000)\n",
    "(avg_scores,avg_f1) = SVMClassification(svc)\n",
    "\n",
    "print('Linear accuracy    ' + str(avg_scores))\n",
    "print('Linear F1-measure  ' + str(avg_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial accuracy(d=2,r=-0.5)    0.45576923076923076\n",
      "Polynomial f1-measure(d=2,r=-0.5)  0.45576923076923076\n",
      "\n",
      "Polynomial accuracy(d=3,r=-0.5)    0.7442307692307693\n",
      "Polynomial f1-measure(d=3,r=-0.5)  0.7442307692307693\n",
      "\n",
      "Polynomial accuracy(d=4,r=-0.5)    0.4397435897435898\n",
      "Polynomial f1-measure(d=4,r=-0.5)  0.4397435897435898\n",
      "\n",
      "Polynomial accuracy(d=2,r=0)    0.6923076923076923\n",
      "Polynomial f1-measure(d=2,r=0)  0.6923076923076923\n",
      "\n",
      "Polynomial accuracy(d=3,r=0)    0.6916666666666667\n",
      "Polynomial f1-measure(d=3,r=0)  0.6916666666666667\n",
      "\n",
      "Polynomial accuracy(d=4,r=0)    0.6512820512820514\n",
      "Polynomial f1-measure(d=4,r=0)  0.6512820512820514\n",
      "\n",
      "Polynomial accuracy(d=2,r=0.5)    0.8282051282051283\n",
      "Polynomial f1-measure(d=2,r=0.5)  0.8282051282051283\n",
      "\n",
      "Polynomial accuracy(d=3,r=0.5)    0.8275641025641025\n",
      "Polynomial f1-measure(d=3,r=0.5)  0.8275641025641025\n",
      "\n",
      "Polynomial accuracy(d=4,r=0.5)    0.8198717948717948\n",
      "Polynomial f1-measure(d=4,r=0.5)  0.8198717948717948\n",
      "\n",
      "Polynomial accuracy(d=2,r=1)    0.8673076923076923\n",
      "Polynomial f1-measure(d=2,r=1)  0.8673076923076923\n",
      "\n",
      "Polynomial accuracy(d=3,r=1)    0.85\n",
      "Polynomial f1-measure(d=3,r=1)  0.85\n",
      "\n",
      "Polynomial accuracy(d=4,r=1)    0.8423076923076923\n",
      "Polynomial f1-measure(d=4,r=1)  0.8423076923076923\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r=[-.5, 0, .5,1 ]\n",
    "d=[2,3,4]\n",
    "\n",
    "import itertools\n",
    "for r,d in itertools.product(r,d):\n",
    "    svc = svm.SVC(kernel = 'poly',max_iter=10000,degree = d, coef0 = r)\n",
    "    (avg_scores,avg_f1) = SVMClassification(svc)\n",
    "    \n",
    "    print('Polynomial accuracy(d={},r={})    '.format(d,r) +str(avg_scores) )\n",
    "    print('Polynomial f1-measure(d={},r={})  '.format(d,r) +str(avg_f1) +'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## degree \n",
    "It appears that the degree parameter controls the flexibility of the decision boundary. Higher degree kernels yield a more flexible decision boundary.\n",
    "\n",
    "## coef0\n",
    "Independent term in kernel function.it is constant parameter in kernel formula. By adjusting it correctly, the accuracy of the model can be improved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gussian RBF SVM parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBF accuracy(gamma0.001)    0.8282051282051281\n",
      "RBF f1-measure(dgamma0.001)  0.8282051282051281\n",
      "\n",
      "RBF accuracy(gamma0.005)    0.8423076923076923\n",
      "RBF f1-measure(dgamma0.005)  0.8423076923076923\n",
      "\n",
      "RBF accuracy(gamma0.01)    0.8339743589743589\n",
      "RBF f1-measure(dgamma0.01)  0.8339743589743589\n",
      "\n",
      "RBF accuracy(gamma0.15)    0.6666666666666667\n",
      "RBF f1-measure(dgamma0.15)  0.6666666666666667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gamma = [0.001 , 0.005,0.01,0.15]\n",
    "for g in gamma:\n",
    "    svc = svm.SVC(kernel = 'rbf',max_iter=10000,gamma = g)\n",
    "    (avg_scores,avg_f1) = SVMClassification(svc)\n",
    "    \n",
    "    print('RBF accuracy(gamma{})    '.format(g) +str(avg_scores) )\n",
    "    print('RBF f1-measure(dgamma{})  '.format(g) +str(avg_f1) +'\\n')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gamma\n",
    "Intuitively, the gamma parameter defines how far the influence of a single training example reaches, with low values meaning 'far' and high values meaning 'close'. The gamma parameters can be seen as the inverse of the radius of influence of samples selected by the model as support vectors.\n",
    "\n",
    "The behavior of the model is very sensitive to the gamma parameter. If gamma is too large, the radius of the area of influence of the support vectors only includes the support vector itself and no amount of regularization with C will be able to prevent overfitting.\n",
    "\n",
    "When gamma is very small, the model is too constrained and cannot capture the complexity or “shape” of the data. The region of influence of any selected support vector would include the whole training set. The resulting model will behave similarly to a linear model with a set of hyperplanes that separate the centers of high density of any pair of two classes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid accuracy(r=-0.5)    0.8435897435897436\n",
      "Sigmoid f1-measure(r=-0.5)  0.8435897435897436\n",
      "\n",
      "Sigmoid accuracy(r=0)    0.8589743589743591\n",
      "Sigmoid f1-measure(r=0)  0.8589743589743591\n",
      "\n",
      "Sigmoid accuracy(r=0.5)    0.8743589743589745\n",
      "Sigmoid f1-measure(r=0.5)  0.8743589743589745\n",
      "\n",
      "Sigmoid accuracy(r=1)    0.7480769230769232\n",
      "Sigmoid f1-measure(r=1)  0.7480769230769232\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r=[-.5, 0, .5,1 ]\n",
    "for r in r:\n",
    "    svc = svm.SVC(kernel = 'sigmoid',max_iter=10000,coef0 = r)\n",
    "    (avg_scores,avg_f1) = SVMClassification(svc)\n",
    "    \n",
    "    print('Sigmoid accuracy(r={})    '.format(r) +str(avg_scores) )\n",
    "    print('Sigmoid f1-measure(r={})  '.format(r) +str(avg_f1) +'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# conclusion\n",
    "based on resuls, the best model is Sigmoid Kernel with r=0.5 which result is 87 percent model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
